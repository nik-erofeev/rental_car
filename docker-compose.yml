services:
  postgres:
    container_name: ${DOCKER_NAME}_postgres
    image: postgres:15
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${DB__USER}
      POSTGRES_PASSWORD: ${DB__PASSWORD}
      POSTGRES_DB: ${DB__NAME}
    volumes:
      - db_data:/var/lib/postgresql/data
    networks:
      - custom
    ports:
      - "15432:5432"
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${DB__USER} -d ${DB__NAME}" ]
      interval: 10s
      timeout: 5s
      retries: 3

  backend:
    container_name: ${DOCKER_NAME}_api
    build:
      context: .
    restart: unless-stopped
    command: ["/app/docker/app.sh"]   # старт скрипт: миграции + uvicorn
    ports:
      - "8000:8000"
    depends_on:
      - postgres
      - kafka
    env_file:
      - .env
    networks:
      - custom
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/check_database" ]
      interval: 30s
      timeout: 5s
      retries: 3

  # для логов grafana-dashboard
  loki:
    container_name: ${DOCKER_NAME}_loki
    image: grafana/loki:2.8.2
    restart: unless-stopped
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./docker/loki-config.yaml:/etc/loki/local-config.yaml:ro
    networks:
      - custom

  # для loki
  promtail:
    container_name: ${DOCKER_NAME}_promtail
    image: grafana/promtail:2.8.2
    restart: unless-stopped
    ports:
      - "9080:9080"
    volumes:
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./docker/promtail/config.yaml:/etc/promtail/config.yaml:ro
    command: -config.file=/etc/promtail/config.yaml
    networks:
      - custom
    depends_on:
      - loki

  grafana:
    container_name: ${DOCKER_NAME}_grafana
    image: grafana/grafana:12.1.0
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
      - GF_LOG_LEVEL=debug
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
      - loki
    networks:
      - custom

  # импорт dashboards (postgres или fastapi)
  grafana_import_16110:
    image: alpine:3.19
    container_name: ${DOCKER_NAME}_grafana_import_16110
    depends_on:
      - grafana
    environment:
      - GRAFANA_USER=${GRAFANA_ADMIN_USER:-admin}
      - GRAFANA_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
    entrypoint: ["sh", "/scripts/import-dashboard.sh"]
    volumes:
      - ./docker/grafana/import-dashboard.sh:/scripts/import-dashboard.sh:ro
      - ./docker/grafana/16110_rev4.json:/dashboards/16110_rev4.json:ro
    networks:
      - custom

  # импорт dashboards (postgres или fastapi)
  grafana_import_13115:
    image: alpine:3.19
    container_name: ${DOCKER_NAME}_grafana_import_13115
    depends_on:
      - grafana
    environment:
      - GRAFANA_USER=${GRAFANA_ADMIN_USER:-admin}
      - GRAFANA_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - DASHBOARD_PATH=/dashboards/13115_rev1.json
    volumes:
      - ./docker/grafana/13115_rev1.json:/dashboards/13115_rev1.json:ro
      - ./docker/grafana/import-local.sh:/scripts/import-local.sh:ro
    entrypoint: ["sh", "/scripts/import-local.sh"]
    networks:
      - custom

  # импорт dashboards (faststream)
  grafana_import_22130:
    image: alpine:3.19
    container_name: ${DOCKER_NAME}_grafana_import_22130
    depends_on:
      - grafana
    environment:
      - GRAFANA_USER=${GRAFANA_ADMIN_USER:-admin}
      - GRAFANA_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - DASHBOARD_PATH=/dashboards/22130_rev3.json
    volumes:
      - ./docker/grafana/22130_rev3.json:/dashboards/22130_rev3.json:ro
      - ./docker/grafana/import-local.sh:/scripts/import-local.sh:ro
    entrypoint: ["sh", "/scripts/import-local.sh"]
    networks:
      - custom


  prometheus:
    container_name: ${DOCKER_NAME}_prometheus
    image: prom/prometheus:v2.53.0
    restart: unless-stopped
    ports:
      - "9090:9090"
    command:
      - --config.file=/etc/prometheus/prometheus.yml
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    networks:
      - custom
    depends_on:
      - backend

  postgres_exporter:
    container_name: ${DOCKER_NAME}_postgres_exporter
    image: wrouesnel/postgres_exporter:latest
    restart: unless-stopped
    env_file:
      - .env
    environment:
      DATA_SOURCE_NAME: "postgresql://${DB__USER}:${DB__PASSWORD}@postgres:5432/${DB__NAME}?sslmode=disable"
    ports:
      - "9187:9187"
    depends_on:
      - postgres
    networks:
      - custom

  elasticsearch:
    # Хранилище логов (single-node, без security для локалки)
    container_name: ${DOCKER_NAME}_elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.4
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    networks:
      - custom

  kibana:
    # UI для поиска по логам/создания data views
    container_name: ${DOCKER_NAME}_kibana
    image: docker.elastic.co/kibana/kibana:8.13.4
    restart: unless-stopped
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - custom

  kibana_setup:
    # Одноразовый init: создаёт Data View в Kibana через API
    container_name: ${DOCKER_NAME}_kibana_setup
    image: curlimages/curl:8.8.0
    depends_on:
      - kibana
    entrypoint: ["/bin/sh", "/app/docker/elastic/kibana_setup.sh"]
    volumes:
      - ./docker/elastic/kibana_setup.sh:/app/docker/elastic/kibana_setup.sh:ro
    environment:
      - KIBANA_URL=http://kibana:5601
      - DATA_VIEW_NAME=rental_car_api_backend
      - DATA_VIEW_TITLE=filebeat-*
      - TIME_FIELD=@timestamp
    networks:
      - custom

  filebeat:
    # Агенt доставки логов контейнеров в Elasticsearch
    container_name: ${DOCKER_NAME}_filebeat
    image: docker.elastic.co/beats/filebeat:8.13.4
    restart: unless-stopped
    user: root
    depends_on:
      - backend
      - elasticsearch
    volumes:
      - ./docker/elastic/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro  # конфиг Filebeat
      - /var/lib/docker/containers:/var/lib/docker/containers:ro   # доступ к JSON-логам Docker
      - /var/run/docker.sock:/var/run/docker.sock:ro               # метаданные контейнеров
      - filebeat_data:/usr/share/filebeat/data                     # реестр файлов/смещения
    networks:
      - custom

  kafka:
      image: bitnami/kafka:3.5.0
      container_name: kafka
      hostname: kafka
      ports:
        - "9092:9092"
        - "29092:29092"
      environment:
        # Включаем KRaft (без ZooKeeper)
        - KAFKA_ENABLE_KRAFT=yes
        - KAFKA_CFG_NODE_ID=1
        - KAFKA_CFG_PROCESS_ROLES=broker,controller
        - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER

        # Три листенера: внутренний (PLAINTEXT), внешний (OUTSIDE), контроллер (CONTROLLER)
        - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,OUTSIDE://:29092,CONTROLLER://:9093

        # Протоколы
        - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,OUTSIDE:PLAINTEXT,CONTROLLER:PLAINTEXT

        # Рекламируемые адреса:
        # - Внутри Docker: kafka:9092
        # - С хоста: localhost:29092
        - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,OUTSIDE://localhost:29092

        # Указываем, что OUTSIDE слушает на localhost:29092
        - KAFKA_CFG_LISTENER_NAME_OUTSIDE_ADVERTISED_HOST_NAME=localhost
        - KAFKA_CFG_LISTENER_NAME_OUTSIDE_ADVERTISED_PORT=29092

        # Кворум контроллера
        - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093

        # ID брокера
        - KAFKA_BROKER_ID=1

        # Разрешить plaintext (для тестов)
        - ALLOW_PLAINTEXT_LISTENER=yes

      networks:
        - custom
      restart: unless-stopped
      healthcheck:
        test: ["CMD", "bash", "-lc", "</dev/tcp/localhost/9092"]
        interval: 10s
        timeout: 5s
        retries: 12

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8090:8080"
    restart: always
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=  # не нужен в KRaft режиме, можно оставить пустым
    networks:
      - custom
    depends_on:
      - kafka

  # worker + service(отправляет на почту якобы)
  fs-broker:
    build:
      context: .
      dockerfile: fs_subscriber/Dockerfile
    container_name: ${DOCKER_NAME}_fs_broker
    command: ["broker"]
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - FS__FASTSTREAM__KAFKA_URL=kafka:9092
      - FS__FASTSTREAM__SUBJECT=${FS__FASTSTREAM__SUBJECT:-user-register}
      - FS__LOGGING__LOG_LEVEL=${FS__LOGGING__LOG_LEVEL:-info}
    volumes:
      - ./fs_subscriber:/app/fs_subscriber
    networks:
      - custom
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    ports:
      - "8001:8000"  # внешние /health и /metrics для fs_subscriber

  # docs по свагеру broker's
  fs-docs:
    build:
      context: .
      dockerfile: fs_subscriber/Dockerfile
    container_name: ${DOCKER_NAME}_fs_docs
    command: ["docs"]
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - FS__FASTSTREAM__KAFKA_URL=kafka:9092
      - FS__FASTSTREAM__SUBJECT=${FS__FASTSTREAM__SUBJECT:-user-register}
      - FS__LOGGING__LOG_LEVEL=${FS__LOGGING__LOG_LEVEL:-info}
    ports:
      - "8081:8081"
    volumes:
      - ./fs_subscriber:/app/fs_subscriber
    networks:
      - custom
    depends_on:
      - kafka




volumes:
  db_data:
  es_data:
  filebeat_data:
  grafana_data:


networks:
  custom:
    driver: bridge